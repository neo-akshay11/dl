{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65f198bb-a7e6-4217-b1d3-19c0b03a5cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples (normal, class=1): 2919\n",
      "Test samples (total): 4998\n",
      "  - Normal (class=1): 2919\n",
      "  - Anomaly (class=0): 2079\n",
      "Feature dimensions: 140\n",
      "Epoch 1/10\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5430 - mae: 0.5227 - val_loss: 0.2653 - val_mae: 0.3550\n",
      "Epoch 2/10\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 947us/step - loss: 0.1981 - mae: 0.3061 - val_loss: 0.1672 - val_mae: 0.2757\n",
      "Epoch 3/10\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1397 - mae: 0.2550 - val_loss: 0.1299 - val_mae: 0.2390\n",
      "Epoch 4/10\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - loss: 0.1090 - mae: 0.2241 - val_loss: 0.1093 - val_mae: 0.2175\n",
      "Epoch 5/10\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - loss: 0.0940 - mae: 0.2073 - val_loss: 0.0996 - val_mae: 0.2068\n",
      "Epoch 6/10\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step - loss: 0.0857 - mae: 0.1976 - val_loss: 0.0930 - val_mae: 0.1986\n",
      "Epoch 7/10\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - loss: 0.0805 - mae: 0.1913 - val_loss: 0.0896 - val_mae: 0.1947\n",
      "Epoch 8/10\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - loss: 0.0764 - mae: 0.1864 - val_loss: 0.0857 - val_mae: 0.1892\n",
      "Epoch 9/10\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step - loss: 0.0731 - mae: 0.1825 - val_loss: 0.0835 - val_mae: 0.1858\n",
      "Epoch 10/10\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - loss: 0.0706 - mae: 0.1795 - val_loss: 0.0813 - val_mae: 0.1841\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315us/step\n",
      "\n",
      "Threshold (95th percentile of training errors): 0.168744\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2069   10]\n",
      " [ 146 2773]]\n",
      "\n",
      "Confusion Matrix explanation:\n",
      "True Anomalies correctly identified: 2069\n",
      "True Anomalies incorrectly labeled as Normal: 10\n",
      "True Normals incorrectly labeled as Anomaly: 146\n",
      "True Normals correctly identified: 2773\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Anomaly (0)       0.93      1.00      0.96      2079\n",
      "  Normal (1)       1.00      0.95      0.97      2919\n",
      "\n",
      "    accuracy                           0.97      4998\n",
      "   macro avg       0.97      0.97      0.97      4998\n",
      "weighted avg       0.97      0.97      0.97      4998\n",
      "\n",
      "\n",
      "Accuracy: 0.9688\n",
      "Precision (for anomaly detection): 0.9341\n",
      "Recall (for anomaly detection): 0.9952\n",
      "F1-Score (for anomaly detection): 0.9637\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "\n",
    "# a. Load and preprocess ECG dataset\n",
    "data = pd.read_csv('/Users/akshay/Downloads/demo_dl/datasets1/ECGdataset(Ass4)/ecg_autoencoder_dataset.csv', header=None)\n",
    "\n",
    "# Last column (140) is the class label, rest are features\n",
    "X = data.iloc[:, :-1].values  # All columns except last\n",
    "y = data.iloc[:, -1].values   # Last column is the label (0=anomaly, 1=normal)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Separate normal data (Class = 1) for training the autoencoder\n",
    "x_train = X_scaled[y == 1]  # Train only on normal heartbeats\n",
    "\n",
    "# Test data (normal + anomalies)\n",
    "x_test = X_scaled\n",
    "y_test = y\n",
    "\n",
    "print(f\"Training samples (normal, class=1): {x_train.shape[0]}\")\n",
    "print(f\"Test samples (total): {x_test.shape[0]}\")\n",
    "print(f\"  - Normal (class=1): {np.sum(y_test == 1)}\")\n",
    "print(f\"  - Anomaly (class=0): {np.sum(y_test == 0)}\")\n",
    "print(f\"Feature dimensions: {x_train.shape[1]}\")\n",
    "\n",
    "# b. Build Autoencoder model\n",
    "input_dim = x_train.shape[1]  # 140 features\n",
    "inp = Input((input_dim,))\n",
    "enc = Dense(64, activation='relu')(inp)\n",
    "lat = Dense(32, activation='relu')(enc)\n",
    "dec = Dense(64, activation='relu')(lat)\n",
    "out = Dense(input_dim, activation='linear')(dec)\n",
    "model = Model(inp, out)\n",
    "\n",
    "# c. Compile & Train\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "history = model.fit(x_train, x_train, epochs=10, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "# d. Reconstruction on test data\n",
    "reconstructions = model.predict(x_test)\n",
    "\n",
    "# e. Calculate reconstruction error\n",
    "mse = np.mean(np.power(x_test - reconstructions, 2), axis=1)\n",
    "\n",
    "# f. Set threshold for anomaly detection (using 95th percentile of training errors)\n",
    "train_reconstructions = model.predict(x_train)\n",
    "train_mse = np.mean(np.power(x_train - train_reconstructions, 2), axis=1)\n",
    "threshold = np.percentile(train_mse, 95)\n",
    "print(f\"\\nThreshold (95th percentile of training errors): {threshold:.6f}\")\n",
    "\n",
    "# g. Predict anomalies (mse > threshold means anomaly, so predict 0)\n",
    "y_pred = (mse > threshold).astype(int)  # 1 if mse > threshold (anomaly)\n",
    "y_pred = 1 - y_pred  # Flip: 0=anomaly, 1=normal to match original labels\n",
    "\n",
    "# h. Evaluation\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print(\"\\nConfusion Matrix explanation:\")\n",
    "print(f\"True Anomalies correctly identified: {cm[0,0]}\")\n",
    "print(f\"True Anomalies incorrectly labeled as Normal: {cm[0,1]}\")\n",
    "print(f\"True Normals incorrectly labeled as Anomaly: {cm[1,0]}\")\n",
    "print(f\"True Normals correctly identified: {cm[1,1]}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Anomaly (0)', 'Normal (1)']))\n",
    "\n",
    "print(f\"\\nAccuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "\n",
    "# Additional metrics\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "print(f\"Precision (for anomaly detection): {precision_score(y_test, y_pred, pos_label=0):.4f}\")\n",
    "print(f\"Recall (for anomaly detection): {recall_score(y_test, y_pred, pos_label=0):.4f}\")\n",
    "print(f\"F1-Score (for anomaly detection): {f1_score(y_test, y_pred, pos_label=0):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7681d646-7279-4ef6-87f4-85fa5aff06f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
